{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CA1: Dataframe Manipulation with Spotify Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Pandas is an extremely powerful tool to handle large amounts of tabular data. In this compulsory assignment, you will use Pandas to explore one of the TA's personal spotify data in depth. \\\n",
    "\\\n",
    "Additional information:\n",
    "- Feel free to create additional code cells if you feel that one cell per subtask is not sufficient.\n",
    "- Remember, Pandas uses very efficient code to handle large amounts of data. For-loops are not efficient. If you ever have to use a for-loop to loop over the rows in the DataFrame, you have *probably* done something wrong.\n",
    "- Label all graphs and charts if applicable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "I typically enjoy indie and rock music. I am a big fan of everything from old-fashioned rock and roll like Led Zeppelin and Jimi Hendrix, to newer indie artists like Joji and Lana Del Rey. This is why my spotify wrapped for 2023 came as quite a surprise:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"spotifywrapped.PNG\" alt=\"Image Description\" width=\"20%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I'm no hater of pop music, but this was unexpected. \n",
    "For this assignment, you will investigate my listening habits, including a deep dive into my Ariana Grande listening habits, and try to find an answer to why she was my top artist; was there a fault in the spotify algorithm? Am I actually secretly an *Arianator*? (yes, I did have to look that up). Or am I just lying to myself about how often I listen to guilty pleasure music?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Initial loading and exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0 Import necessary libraries: \n",
    "pandas, numpy, matplotlib.pyplot (other libraries such as seaborn or plotly are also allowed if you want prettier plots). It might also be a good idea to use **os** for task 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# ---- Insert other imports ----\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Loading the data\n",
    "Load the dataset in the file `streaming_history_0.csv` into a Pandas DataFrame called `df_spotify_0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spotify_0 = pd.read_csv('spotify_data/streaminghistory0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Help function\n",
    "Use the Python command `help` to help you understand how to use the `pd.DataFrame.head` and `pd.DataFrame.tail` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function tail in module pandas.core.generic:\n",
      "\n",
      "tail(self, n: 'int' = 5) -> 'Self'\n",
      "    Return the last `n` rows.\n",
      "    \n",
      "    This function returns last `n` rows from the object based on\n",
      "    position. It is useful for quickly verifying data, for example,\n",
      "    after sorting or appending rows.\n",
      "    \n",
      "    For negative values of `n`, this function returns all rows except\n",
      "    the first `|n|` rows, equivalent to ``df[|n|:]``.\n",
      "    \n",
      "    If n is larger than the number of rows, this function returns all rows.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    n : int, default 5\n",
      "        Number of rows to select.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    type of caller\n",
      "        The last `n` rows of the caller object.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.head : The first `n` rows of the caller object.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
      "    ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      "    >>> df\n",
      "          animal\n",
      "    0  alligator\n",
      "    1        bee\n",
      "    2     falcon\n",
      "    3       lion\n",
      "    4     monkey\n",
      "    5     parrot\n",
      "    6      shark\n",
      "    7      whale\n",
      "    8      zebra\n",
      "    \n",
      "    Viewing the last 5 lines\n",
      "    \n",
      "    >>> df.tail()\n",
      "       animal\n",
      "    4  monkey\n",
      "    5  parrot\n",
      "    6   shark\n",
      "    7   whale\n",
      "    8   zebra\n",
      "    \n",
      "    Viewing the last `n` lines (three in this case)\n",
      "    \n",
      "    >>> df.tail(3)\n",
      "      animal\n",
      "    6  shark\n",
      "    7  whale\n",
      "    8  zebra\n",
      "    \n",
      "    For negative values of `n`\n",
      "    \n",
      "    >>> df.tail(-3)\n",
      "       animal\n",
      "    3    lion\n",
      "    4  monkey\n",
      "    5  parrot\n",
      "    6   shark\n",
      "    7   whale\n",
      "    8   zebra\n",
      "\n",
      "Help on function head in module pandas.core.generic:\n",
      "\n",
      "head(self, n: 'int' = 5) -> 'Self'\n",
      "    Return the first `n` rows.\n",
      "    \n",
      "    This function returns the first `n` rows for the object based\n",
      "    on position. It is useful for quickly testing if your object\n",
      "    has the right type of data in it.\n",
      "    \n",
      "    For negative values of `n`, this function returns all rows except\n",
      "    the last `|n|` rows, equivalent to ``df[:n]``.\n",
      "    \n",
      "    If n is larger than the number of rows, this function returns all rows.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    n : int, default 5\n",
      "        Number of rows to select.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    same type as caller\n",
      "        The first `n` rows of the caller object.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.tail: Returns the last `n` rows.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
      "    ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      "    >>> df\n",
      "          animal\n",
      "    0  alligator\n",
      "    1        bee\n",
      "    2     falcon\n",
      "    3       lion\n",
      "    4     monkey\n",
      "    5     parrot\n",
      "    6      shark\n",
      "    7      whale\n",
      "    8      zebra\n",
      "    \n",
      "    Viewing the first 5 lines\n",
      "    \n",
      "    >>> df.head()\n",
      "          animal\n",
      "    0  alligator\n",
      "    1        bee\n",
      "    2     falcon\n",
      "    3       lion\n",
      "    4     monkey\n",
      "    \n",
      "    Viewing the first `n` lines (three in this case)\n",
      "    \n",
      "    >>> df.head(3)\n",
      "          animal\n",
      "    0  alligator\n",
      "    1        bee\n",
      "    2     falcon\n",
      "    \n",
      "    For negative values of `n`\n",
      "    \n",
      "    >>> df.head(-3)\n",
      "          animal\n",
      "    0  alligator\n",
      "    1        bee\n",
      "    2     falcon\n",
      "    3       lion\n",
      "    4     monkey\n",
      "    5     parrot\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.DataFrame.tail)\n",
    "help(pd.DataFrame.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Getting an overview\n",
    "Print the first `five` and last `ten` rows of the dataframe. Have a quick look at which columns are in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            endTime            artistName                        trackName  \\\n",
      "0  2022-12-03 02:02  Cigarettes After Sex                            Truly   \n",
      "1  2022-12-03 02:02         Leonard Cohen  Take This Waltz - Paris Version   \n",
      "2  2022-12-06 21:05          Vlad Holiday                 So Damn Into You   \n",
      "3  2022-12-06 21:05                 Lorde                             Team   \n",
      "4  2022-12-06 21:05         Ariana Grande                         Into You   \n",
      "\n",
      "   msPlayed  \n",
      "0   30000.0  \n",
      "1    8210.0  \n",
      "2   37895.0  \n",
      "3    8984.0  \n",
      "4    1221.0  \n",
      "                endTime         artistName                     trackName  \\\n",
      "11949  2023-01-02 20:58      Ariana Grande                    six thirty   \n",
      "11950  2023-01-02 20:58      Leonard Cohen          Thanks for the Dance   \n",
      "11951  2023-01-02 20:59           Des Rocs          Used to the Darkness   \n",
      "11952  2023-01-02 20:59  Caroline Polachek         Hit Me Where It Hurts   \n",
      "11953  2023-01-02 20:59  Caroline Polachek         Hit Me Where It Hurts   \n",
      "11954  2023-01-02 20:59  Kaizers Orchestra                   Resistansen   \n",
      "11955  2023-01-02 20:59           Mr.Kitty                    After Dark   \n",
      "11956  2023-01-02 20:59       daddy's girl  after dark x sweater weather   \n",
      "11957  2023-01-02 20:59       daddy's girl  after dark x sweater weather   \n",
      "11958  2023-01-02 20:59       daddy's girl  after dark x sweater weather   \n",
      "\n",
      "       msPlayed  \n",
      "11949    1699.0  \n",
      "11950   19483.0  \n",
      "11951     185.0  \n",
      "11952     603.0  \n",
      "11953     208.0  \n",
      "11954     208.0  \n",
      "11955  101447.0  \n",
      "11956     301.0  \n",
      "11957     208.0  \n",
      "11958     789.0  \n"
     ]
    }
   ],
   "source": [
    "print(df_spotify_0.head(5))\n",
    "print(df_spotify_0.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Formatting correctly\n",
    "When working with Pandas, it's very useful to have columns which contains dates in a specific format called *datetime*. This allows for efficient manipulation and analysis of time-series data, such as sorting, filtering by date or time, and resampling for different time periods. Figure out which column(s) would be appropriate to convert to datetime, if any, and if so, perform the conversion to the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              endTime            artistName                        trackName  \\\n",
      "0 2022-12-03 02:02:00  Cigarettes After Sex                            Truly   \n",
      "1 2022-12-03 02:02:00         Leonard Cohen  Take This Waltz - Paris Version   \n",
      "2 2022-12-06 21:05:00          Vlad Holiday                 So Damn Into You   \n",
      "3 2022-12-06 21:05:00                 Lorde                             Team   \n",
      "4 2022-12-06 21:05:00         Ariana Grande                         Into You   \n",
      "\n",
      "                 msPlayed  \n",
      "0 1970-01-01 00:00:30.000  \n",
      "1 1970-01-01 00:00:08.210  \n",
      "2 1970-01-01 00:00:37.895  \n",
      "3 1970-01-01 00:00:08.984  \n",
      "4 1970-01-01 00:00:01.221  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_spotify_0['endTime']= pd.to_datetime(df_spotify_0['endTime'])\n",
    "print(df_spotify_0.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Unique artists\n",
    "Find how many unique artists are in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495\n"
     ]
    }
   ],
   "source": [
    "print(len(pd.unique(df_spotify_0['artistName'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 Unique songs\n",
    "Find how many unique songs are in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1308\n"
     ]
    }
   ],
   "source": [
    "print(len(pd.unique(df_spotify_0['trackName'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Questions\n",
    "Q1: Which columns are in the dataset?\n",
    "\n",
    "Q2: What timeframe does the dataset span?\n",
    "\n",
    "Q3: How many unique artists are in the dataset?\n",
    "\n",
    "Q4: How many unique songs are in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['endTime', 'artistName', 'trackName', 'msPlayed']\n",
      "2023-01-02 20:59:00\n",
      "2022-12-03 02:02:00\n",
      "30 days 18:57:00\n",
      "495\n",
      "1308\n"
     ]
    }
   ],
   "source": [
    "#Q1 \n",
    "print(list(df_spotify_0.columns))\n",
    "\n",
    "#Q2\n",
    "print(df_spotify_0['endTime'].max())\n",
    "print(df_spotify_0['endTime'].min())\n",
    "print(df_spotify_0['endTime'].max()-df_spotify_0['endTime'].min())\n",
    "\n",
    "#Q3\n",
    "print(len(pd.unique(df_spotify_0['artistName'])))\n",
    "\n",
    "#Q4\n",
    "print(len(pd.unique(df_spotify_0['trackName'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Working with all the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0 Importing all the dataframes\n",
    "In Task 1, you only worked with about a month worth of data. Now, you will work with over a year worth. \n",
    "\n",
    "In the *spotify_data* folder, there is more than just one listening record. Load each of the 14 listening records into a dataframe (1 dataframe per listening record), and concatenate them together into one large dataframe named `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = 14\n",
    "li = []\n",
    "for i in range(files):\n",
    "    file = 'spotify_data/streaminghistory' + str(i) + '.csv'\n",
    "    df_spotify = pd.read_csv(file)\n",
    "    li.append(df_spotify)\n",
    "\n",
    "df = pd.concat(li, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Sorting by time\n",
    "Datasets often aren't perfect. One example of an issue that could occur is that the time-based data might not be in chronological order. If this were to happen, the rows in your dataframe could be in the wrong order. To ensure this isn't an issue in your dataframe, you should sort the dataframe in chronological order, from oldest to newest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='endTime')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Setting a timeframe\n",
    "For this investigation, we are only interested in investigating listening patterns from **2023**. Remove any data not from **2023** from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 endTime     artistName                        trackName  \\\n",
      "167435  2023-12-07 21:13  Ariana Grande  off the table (with The Weeknd)   \n",
      "167436  2023-12-07 21:14  Ariana Grande                          my hair   \n",
      "167437  2023-12-07 21:14  Leonard Cohen             Thanks for the Dance   \n",
      "167438  2023-12-07 21:17   The Vaccines   Your Love Is My Favourite Band   \n",
      "164529               NaN  The Lumineers                          Ophelia   \n",
      "\n",
      "        msPlayed  \n",
      "167435   13448.0  \n",
      "167436   23757.0  \n",
      "167437    9317.0  \n",
      "167438   14661.0  \n",
      "164529     371.0  \n"
     ]
    }
   ],
   "source": [
    "df = df[~(df['endTime'] < '2023-01-01')]\n",
    "print(df.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Deleting rows\n",
    "Often in Data Science, you will encounter when a row entry has the value *NaN*, indicating missing data. These entries can skew your analysis, leading to inaccurate conclusions. For this task, identify and remove any rows in your DataFrame that contain NaN values. \\\n",
    "Later in the course, you might encounter other techniques of dealing with missing data, typically reffered to as *data imputation*. Here, though, you are just supposed to delete the entire rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Convert from milliseconds to seconds\n",
    "From `msPlayed`, create a new column `secPlayed` with the data converted from milliseconds to seconds. Then delete the column `msPlayed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'msPlayed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'msPlayed'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msecPlayed\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m (\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmsPlayed\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmsPlayed\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3807\u001b[0m     ):\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'msPlayed'"
     ]
    }
   ],
   "source": [
    "df['secPlayed']= (df['msPlayed'] / 1000)\n",
    "df.drop(['msPlayed'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Finding top 10 favorite artists\n",
    "Find the top `ten` artists with the highest total play time (in seconds). Plot your findings in a bar graph. \\\n",
    "(hint: start by creating a new DataFrame with only `artistName` and your time column. To proceed, you will also likely need the `groupby` command from Pandas.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artistName\n",
      "Ariana Grande          169476\n",
      "Joji                   135444\n",
      "The Pretty Reckless    108675\n",
      "Cage The Elephant       93326\n",
      "Lana Del Rey            89098\n",
      "Greta Van Fleet         86923\n",
      "The Neighbourhood       84192\n",
      "Gorillaz                83607\n",
      "Led Zeppelin            75602\n",
      "Arctic Monkeys          75122\n",
      "Name: secPlayed, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['secPlayed'] = df['secPlayed'].astype(int)\n",
    "artist = df['secPlayed'].groupby(df['artistName']).sum().nlargest(10)\n",
    "print(artist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Finding top 10 favorite songs\n",
    "Find the top `ten` songs with the highest play time. Create a graph visualizing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.0 Average listening time by hour\n",
    "Generate a plot that displays the average amount of time that music is played for each hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Morning music and evening music\n",
    "I think many people find that some types of music are more suitable for morning listening and some music is more suitable for evening listening. Create a plot that compares the play time of the artists *Leonard Cohen* and *Rage Against the Machine* on an hour-by-hour basis. See if there are any differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Analysing skipped songs\n",
    "Determining whether a song was skipped or listened to can be challenging. For this analysis, we'll simplify by defining a skipped song as any track played for less than 30 seconds. Conversely, a song played for 30 seconds or more is considered listened to. \\\n",
    " Add a column to your DataFrame to reflect this criteria: set the value to 1 if the song was played for less than 30 seconds (indicating a skipped song), and 0 if it was played for 30 seconds or longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Plotting skipped songs\n",
    "Create a pie-chart that compares amount of skipped songs to amount of non-skipped songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Artists by percentage of songs skipped\n",
    "For each artist in the dataset, calculate which percentage of their songs was skipped. Store this information in a new DataFrame called `df_skipped`. Store the percentage of skipped songs in a new column named `SkipRate`\\\n",
    "\\\n",
    "**Example**: If an artist has **100** songs in your dataset and **25** of these were skipped, the percentage of skipped songs for this artist would be $\\frac{25}{100}=25\\%$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Comparing artists by skip-rate \n",
    "Find the `three` top artists with the lowest skip-rate and the `three` with the highest. Print their names, along with their skip-rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: God Is a Data Scientist - The Ariana Deep-Dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.0 Ariana-DataFrame: \n",
    "Create a new DataFrame called *df_ariana*, containing only rows with music by Ariana Grande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Average skip rate\n",
    "Create a histogram of the distribution of the skip-rate values of the different artists in your DataFrame  `df_skipped`, with skip rates on one axis and number of artists on the other. \\\n",
    "\\\n",
    "Then, retrieve the skip rate for Ariana Grande from your DataFrame `df_skipped`. Run the code in the cell below. Where on this distribution does Ariana Grande fall? Do I skip her songs more than average, or less?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Questions\n",
    "Q1: Did I skip a lot of Ariana Grande's songs, or did I not, compared to the rest of the dataset? \\\n",
    "Q2: What might be some possible reasons for Ariana Grande to be my nr.1 artist?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
